{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (96, 96, 3)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAL_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, hms_dir, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.root_dir = hms_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        for cls_idx, cls_name in enumerate(self.classes):\n",
    "            cls_dir = os.path.join(root_dir, cls_name)\n",
    "            hm_dir = os.path.join(hms_dir, cls_name)\n",
    "            for file_name in os.listdir(cls_dir):\n",
    "                image_path = os.path.join(cls_dir, file_name)\n",
    "                heatmap_path = os.path.join(hm_dir, str(file_name[:-4])+'.npy')\n",
    "                self.samples.append((image_path, cls_idx, heatmap_path))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        file_path, cls_idx, heatmap_path = self.samples[idx]\n",
    "\n",
    "        \n",
    "        image = Image.open(file_path)\n",
    "        heatmap = np.load(heatmap_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "\n",
    "        return image, cls_idx, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "data_path = '../datasets/AffectNet'\n",
    "hm_path = '../datasets/HeatMaps'\n",
    "\n",
    "# Define the data generator\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Define the training data generator\n",
    "train_dataset = PAL_Dataset(\n",
    "    root_dir=data_path, \n",
    "    hms_dir=hm_path,\n",
    "    transform=data_transforms['train']\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, cls_idx, heatmap = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "# Assuming that train_loader returns a tuple (image, cls_idx, heatmap)\n",
    "image, cls_idx, heatmap = next(iter(train_loader))\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "image_np = F.to_pil_image(image[1])  # Convert to PIL Image\n",
    "\n",
    "plt.imshow(image_np)\n",
    "plt.title(f\"Class Index: {cls_idx}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        vgg16 = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        modules = list(vgg16.children())[:-1]\n",
    "        vgg16 = nn.Sequential(*modules)  # output (512, 7, 7)\n",
    "\n",
    "        for p in vgg16.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.feature_extractor = vgg16\n",
    "\n",
    "        self.fc1 = nn.Linear(7 * 7 * 512, 4096)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(4096, 2048)\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(2048, 8)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(-1, 7 * 7 * 512)\n",
    "        x = self.tanh1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.tanh2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        out = self.softmax(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cassifier()\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader, 0), total=len(train_loader)):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            tqdm.write(f'loss: {running_loss / 10:.3f}', end='\\r')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
