{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, auto\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchsummary import summary\n",
    "from datasets import load_dataset\n",
    "import face_recognition\n",
    "from matplotlib.colors import LinearSegmentedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffectNetHqDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item['image']\n",
    "        label = item['label']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PrivilegedAttributionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrivilegedAttributionLoss, self).__init__()\n",
    "\n",
    "    def forward(self, attribution_maps, prior_maps):\n",
    "        # Add a small value to standard deviation to avoid division by zero\n",
    "        epsilon = 1e-8\n",
    "\n",
    "        # Calculate mean and standard deviation for each sample in the batch\n",
    "        mean_al = torch.mean(attribution_maps, dim=[1, 2, 3], keepdim=True)  # Assuming BCHW format\n",
    "        std_al = torch.std(attribution_maps, dim=[1, 2, 3], keepdim=True) + epsilon\n",
    "\n",
    "        # Replace NaN values with a default value (e.g., 0) in attribution_maps, mean_al, std_al, and prior_maps\n",
    "        attribution_maps = torch.where(torch.isnan(attribution_maps), torch.zeros_like(attribution_maps), attribution_maps)\n",
    "        mean_al = torch.where(torch.isnan(mean_al), torch.zeros_like(mean_al), mean_al)\n",
    "        std_al = torch.where(torch.isnan(std_al), torch.zeros_like(std_al), std_al)\n",
    "        prior_maps = torch.where(torch.isnan(prior_maps), torch.zeros_like(prior_maps), prior_maps)\n",
    "\n",
    "        # Calculate the PAL loss\n",
    "        # Ensure that the broadcasting in the subtraction and division is correct\n",
    "        pal_loss = -torch.sum((attribution_maps - mean_al) / std_al * prior_maps, dim=[1, 2, 3])\n",
    "\n",
    "        # Return the mean loss over the batch\n",
    "        return torch.mean(pal_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "full_dataset = load_dataset(\"Piro17/affectnethq\", split='train')\n",
    "\n",
    "# Split the dataset into train and test subsets\n",
    "train_size = int(0.5 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_subset, test_subset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation((-10, 10)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader using the subsets\n",
    "train_dataset = AffectNetHqDataset(Subset(full_dataset, train_subset.indices), transform=train_transform)\n",
    "test_dataset = AffectNetHqDataset(Subset(full_dataset, test_subset.indices), transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "# Charger le modèle pré-entraîné ResNet50\n",
    "base_model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# Supprimer la dernière couche entièrement connectée (fc)\n",
    "base_model = nn.Sequential(*list(base_model.children())[:-1])\n",
    "\n",
    "# Ajouter une nouvelle couche adaptée à 7 classes\n",
    "num_classes = 7\n",
    "classifier_layer = nn.Linear(2048, num_classes)  # ResNet50 utilise 2048 features avant la couche fc\n",
    "model = nn.Sequential(base_model, nn.Flatten(), classifier_layer)\n",
    "\n",
    "# Afficher la structure du modèle\n",
    "summary(model, (3, 224, 224))  # Assurez-vous d'ajuster les dimensions en fonction de vos données\n",
    "\n",
    "# Identifier la dernière couche de convolution\n",
    "# Pour ResNet50, la dernière couche de convolution est la dernière couche de la partie 'base_model'\n",
    "# Identifier la dernière couche de convolution dans ResNet50\n",
    "# Notez que dans ResNet50, la dernière couche de convolution se trouve dans la dernière \"Bottleneck\"\n",
    "last_conv_layer = list(base_model.children())[-3][2].conv3\n",
    "print(\"last conv layer =\", last_conv_layer)\n",
    "\n",
    "# Définir l'optimiseur\n",
    "optimizer = optim.Adam(model.parameters(), lr=4e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "\n",
    "def heatmap_generator(image):\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "    # Load the pre-trained facial landmark model\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image, face_locations)\n",
    "\n",
    "    h,w = image.shape[:2]\n",
    "    lm = np.zeros([h,w])\n",
    "\n",
    "    # Draw facial landmarks on the image\n",
    "    for face_landmarks in face_landmarks_list:\n",
    "        for landmark_type, landmarks in face_landmarks.items():\n",
    "            for (x, y) in landmarks:\n",
    "                if x < h and y < w :\n",
    "                    lm[y,x] = 1\n",
    "\n",
    "    heatmap = cv2.GaussianBlur(lm, [59,59], 3)         \n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def generate_batch_heatmaps(images, heatmap_generator):\n",
    "    batch_heatmaps = torch.zeros_like(images)\n",
    "\n",
    "    for i in range(images.size(0)):\n",
    "        # Convertir le tenseur PyTorch en tableau NumPy pour l'image i\n",
    "        image_np = images[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        image_np = (image_np * 255).astype(np.uint8) if image_np.dtype != np.uint8 else image_np\n",
    "        image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        # Générer la heatmap pour l'image actuelle\n",
    "        heatmap_np = heatmap_generator(image_np)\n",
    "        heatmap_tensor = torch.from_numpy(heatmap_np).float().unsqueeze(0)\n",
    "\n",
    "        # Normaliser la heatmap et l'adapter à la taille de l'image\n",
    "        heatmap_tensor = heatmap_tensor / torch.max(heatmap_tensor)\n",
    "        heatmap_tensor = heatmap_tensor.repeat(3, 1, 1)\n",
    "\n",
    "        # Stocker la heatmap dans le tenseur batch\n",
    "        batch_heatmaps[i] = heatmap_tensor\n",
    "    \n",
    "    return batch_heatmaps\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def plot_element(images, batch_heatmaps, attribution_maps, gradients, i):\n",
    "    plt.figure(figsize=(12, 8))  # Agrandir la figure pour accueillir toutes les visualisations\n",
    "    # Afficher l'image original\n",
    "    plt.subplot(2, 4, 1)\n",
    "    image_to_show = images[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    image_to_show = (image_to_show - image_to_show.min()) / (image_to_show.max() - image_to_show.min())  # Normalisation\n",
    "    image_to_show = np.clip(image_to_show, 0, 1) \n",
    "    plt.imshow(image_to_show)\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Afficher la heatmap\n",
    "    plt.subplot(2, 4, 2)\n",
    "    heatmap_to_show = batch_heatmaps[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    heatmap_to_show = np.clip(heatmap_to_show, 0, 1) \n",
    "    plt.imshow(heatmap_to_show)\n",
    "    plt.title('Heatmap')\n",
    "\n",
    "    # Afficher chaque canal de la carte d'attribution\n",
    "    plt.subplot(2, 4, 3)\n",
    "    attribution_to_show = attribution_maps[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Normaliser les valeurs de la carte d'attribution dans la plage [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    attribution_norm = scaler.fit_transform(attribution_to_show.reshape(-1, 1)).reshape(attribution_to_show.shape)\n",
    "    \n",
    "    attribution_mean = np.mean(attribution_norm, axis=2)\n",
    "    \n",
    "    # Appliquer une colormap 'jet' pour obtenir une carte d'attribution colorée\n",
    "    cmap = plt.get_cmap('bwr')\n",
    "    attribution_colored = cmap(attribution_mean)\n",
    "\n",
    "    # Supprimer le canal alpha retourné par la colormap\n",
    "    attribution_colored = attribution_colored[..., :3]\n",
    "    overlayed_image = (image_to_show) * 0.2 + attribution_colored * 0.9  # Ajustez la transparence ici\n",
    "    overlayed_image = np.clip(overlayed_image, 0, 1) \n",
    "    plt.imshow(overlayed_image)\n",
    "    plt.title(\"Carte d'atribution\")\n",
    "\n",
    "    # Afficher le gradient de sortie sur l'image originale\n",
    "    plt.subplot(2, 4, 4)\n",
    "    gradients_to_show = gradients[i].detach().permute(1, 2, 0).cpu().numpy()\n",
    "    gradients_to_show = np.abs(gradients_to_show)\n",
    "    gradients_to_show /= np.max(gradients_to_show)\n",
    "                \n",
    "    # Superposer le gradient sur l'image originale\n",
    "    overlayed_image = (gradients_to_show * 1.5 + image_to_show * 0.2)\n",
    "    overlayed_image = np.clip(overlayed_image, 0, 1) \n",
    "    plt.imshow(overlayed_image)\n",
    "    plt.title('Gradient')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "num_epochs = 10\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss_values = [] \n",
    "accuracy_values = []  \n",
    "lr = 4e-5\n",
    "power = 5\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, num_epochs, initial_lr, power):\n",
    "    \"\"\"Ajuste le taux d'apprentissage selon une politique de décroissance polynomiale.\"\"\"\n",
    "    lr = initial_lr * (1 - (epoch / num_epochs)) ** power\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    adjust_learning_rate(optimizer, epoch, num_epochs, lr, power)  # Mise à jour du taux d'apprentissage\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_pal_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    total_samples = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # Initialiser un tenseur pour stocker toutes les heatmaps\n",
    "        batch_heatmaps = generate_batch_heatmaps(images, heatmap_generator)\n",
    "\n",
    "        # Ensure that images require gradients\n",
    "        images.requires_grad_()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        labels = labels.long()\n",
    "\n",
    "        # Calcul de la classification loss\n",
    "        classification_loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass for gradients with respect to the input images\n",
    "        classification_loss.backward(retain_graph=True)  \n",
    "        gradients = images.grad\n",
    "\n",
    "        # Compute the attribution maps as the element-wise product of the gradients and the input images\n",
    "        attribution_maps = gradients * images\n",
    "\n",
    "        # Compute the PAL loss using the attribution maps and the prior maps\n",
    "        pal_loss_fn = PrivilegedAttributionLoss()\n",
    "        pal_loss = pal_loss_fn(attribution_maps, batch_heatmaps)\n",
    "\n",
    "        # Calcul de la PAL loss et de la classification loss\n",
    "        total_loss = classification_loss + pal_loss\n",
    "\n",
    "        # Backpropagation et optimisation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Mise à jour des running loss et PAL loss\n",
    "        running_loss += classification_loss.item()\n",
    "        running_pal_loss += pal_loss.item()         \n",
    "  \n",
    "        # Calcul de la classification loss et de la PAL loss\n",
    "        total_loss = classification_loss + pal_loss\n",
    "\n",
    "        # Mise à jour des running loss et PAL loss\n",
    "        running_loss += classification_loss.item()\n",
    "        running_pal_loss += pal_loss.item()\n",
    "\n",
    "        if epoch == 0:\n",
    "            plot_element(images, batch_heatmaps, attribution_maps, gradients, 0)\n",
    "\n",
    "        # Mise à jour des running loss et PAL loss\n",
    "        running_loss += classification_loss.item()\n",
    "        running_pal_loss += pal_loss.item()\n",
    "\n",
    "        # Calcul de l'accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calcul des moyennes pour l'époque\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_pal_loss = running_pal_loss / len(train_loader)\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "\n",
    "    # Ajouter les valeurs moyennes aux listes\n",
    "    loss_values.append(epoch_loss)\n",
    "    accuracy_values.append(epoch_acc)\n",
    "\n",
    "    # Affichage des résultats pour l'époque\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print(f'Loss: {epoch_loss:.4f}, PAL Loss: {epoch_pal_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Liste de longueurs de vecteur que vous souhaitez utiliser\n",
    "vector_lengths = np.linspace(0, len(loss_values), len(loss_values))\n",
    "\n",
    "# Plot de la perte en fonction de la longueur du vecteur\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(vector_lengths, loss_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perte')\n",
    "plt.title(\"Loss en fonction de l'epoch\")\n",
    "\n",
    "# Plot de la précision en fonction de la longueur du vecteur\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(vector_lengths, accuracy_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy en fonction de l'epoch\")\n",
    "\n",
    "plt.tight_layout()  # Pour éviter que les titres se chevauchent\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
